{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syarifuddin22/pakcoy-diseases-detection/blob/main/Syarif_TA_Pakcoy%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5rNw7DKjuxO",
        "outputId": "b2c53e3d-941e-4be8-fb4c-5613e31a07c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0pTVWCKEkzva",
        "outputId": "7da439a7-e1ca-4b2a-dad1-ab204c38f728"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ouy3MSmYk75i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL9kEbAKlMKY"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/TA/databaru/train'\n",
        "valid_path = '/content/drive/MyDrive/TA/databaru/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58FSKrQHpOuh"
      },
      "outputs": [],
      "source": [
        "\n",
        "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LftUJge5pIld"
      },
      "outputs": [],
      "source": [
        "# don't train existing weights\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx3PfZByy0fQ"
      },
      "outputs": [],
      "source": [
        " # useful for getting number of output classes\n",
        "train_dir = glob('/content/drive/MyDrive/TA/databaru/train*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi7fRttYRZTp",
        "outputId": "b71792ce-94a8-4026-f21a-164030515549"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/TA/databaru/train']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "train_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAhG4XYkzKHi"
      },
      "outputs": [],
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(resnet.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_uwTrLvQsuB"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(len(train_dir), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=resnet.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8BVSrBRBuT5"
      },
      "outputs": [],
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (224,224,3)),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(256,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation= 'relu'),\n",
        "  tf.keras.layers.Dropout(0.1),                                                  #menambahkan dropout\n",
        "  tf.keras.layers.Dense(4, activation= 'softmax')\n",
        "])\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIQTc-bSBziY"
      },
      "outputs": [],
      "source": [
        "from numpy.ma.core import resize\n",
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import math, os, sys\n",
        "from skimage.io import imsave, imread\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Melnl-lnQwrS",
        "outputId": "b9b0e9bc-5ebe-458c-cbac-65273b7cdde5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 111, 111, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 26, 26, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 24, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 12, 12, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 36864)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               18874880  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,265,348\n",
            "Trainable params: 19,265,348\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# view the structure of the model\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 5:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,\n",
        "    update_freq='epoch', embeddings_freq=0,\n",
        "    embeddings_metadata=None\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBCdE7-TB4z4",
        "outputId": "2d43d3df-4055-4507-85c2-072d1f220951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1263 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/TA/databaru/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd-Ek5oyCgj9",
        "outputId": "c6c0490e-6cb4-4fe9-84e5-84bd4e904104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/TA/databaru/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NX0iIO5lGJDT",
        "outputId": "c1b81452-8cb4-4cca-ef84-a774f402ecec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 145s 4s/step - loss: 1.1673 - accuracy: 0.4933 - val_loss: 2.0096 - val_accuracy: 0.0333\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 127s 3s/step - loss: 0.6475 - accuracy: 0.6888 - val_loss: 5.5900 - val_accuracy: 0.3000\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 130s 3s/step - loss: 0.4793 - accuracy: 0.8013 - val_loss: 6.8237 - val_accuracy: 0.4333\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 130s 3s/step - loss: 0.3060 - accuracy: 0.8757 - val_loss: 8.4648 - val_accuracy: 0.4000\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 128s 3s/step - loss: 0.2685 - accuracy: 0.9097 - val_loss: 6.8231 - val_accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 126s 3s/step - loss: 0.2040 - accuracy: 0.9287 - val_loss: 12.5063 - val_accuracy: 0.4667\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 126s 3s/step - loss: 0.1070 - accuracy: 0.9636 - val_loss: 12.0120 - val_accuracy: 0.4667\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 127s 3s/step - loss: 0.0605 - accuracy: 0.9802 - val_loss: 19.6568 - val_accuracy: 0.4333\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 126s 3s/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 14.6875 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 126s 3s/step - loss: 0.0484 - accuracy: 0.9842 - val_loss: 12.2397 - val_accuracy: 0.4333\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 129s 3s/step - loss: 0.0975 - accuracy: 0.9675 - val_loss: 9.7023 - val_accuracy: 0.4667\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 129s 3s/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 16.4654 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 127s 3s/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 17.3800 - val_accuracy: 0.4667\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 128s 3s/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 28.8934 - val_accuracy: 0.4333\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 131s 3s/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 17.8731 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 127s 3s/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 15.8650 - val_accuracy: 0.4667\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0239 - accuracy: 0.9905 - val_loss: 13.8116 - val_accuracy: 0.4667\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 22.2733 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 20.8854 - val_accuracy: 0.4667\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0239 - accuracy: 0.9905 - val_loss: 15.8719 - val_accuracy: 0.4333\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 122s 3s/step - loss: 0.0209 - accuracy: 0.9905 - val_loss: 23.2266 - val_accuracy: 0.4333\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 124s 3s/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 23.1227 - val_accuracy: 0.4667\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 126s 3s/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 26.0634 - val_accuracy: 0.5333\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 124s 3s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 25.0795 - val_accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 26.7417 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0146 - accuracy: 0.9929 - val_loss: 23.8132 - val_accuracy: 0.4333\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 122s 3s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 26.1790 - val_accuracy: 0.4333\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 5.7269e-04 - accuracy: 1.0000 - val_loss: 28.1538 - val_accuracy: 0.4667\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 6.5345e-04 - accuracy: 1.0000 - val_loss: 30.2918 - val_accuracy: 0.4333\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 124s 3s/step - loss: 2.9587e-04 - accuracy: 1.0000 - val_loss: 29.2773 - val_accuracy: 0.4667\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 15.7007 - val_accuracy: 0.4667\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 124s 3s/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 18.9893 - val_accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 17.8272 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 122s 3s/step - loss: 0.0128 - accuracy: 0.9952 - val_loss: 23.9025 - val_accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 26.1099 - val_accuracy: 0.4333\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 23.1606 - val_accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 122s 3s/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 29.5920 - val_accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0201 - accuracy: 0.9952 - val_loss: 22.9060 - val_accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 122s 3s/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 23.6977 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 23.2493 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 4.8567e-04 - accuracy: 1.0000 - val_loss: 26.7944 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 27.5631 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 5.6239e-04 - accuracy: 1.0000 - val_loss: 26.7302 - val_accuracy: 0.4333\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 30.4504 - val_accuracy: 0.4667\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 124s 3s/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 32.0535 - val_accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 34.7061 - val_accuracy: 0.4333\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0038 - accuracy: 0.9976 - val_loss: 29.8758 - val_accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.0389 - accuracy: 0.9913 - val_loss: 16.3434 - val_accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 126s 3s/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 25.1862 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 123s 3s/step - loss: 7.4715e-04 - accuracy: 1.0000 - val_loss: 26.1427 - val_accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 8.6173e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bd3f0dd5b756>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Run the cell. It will take some time to execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/TA/databaru/test/SEHAT/sehat 9.jpg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/TA/databaru/test/SEHAT/sehat 9.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/TA/databaru/test/SEHAT/sehat 9.jpg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/TA/databaru/test/SEHAT/sehat 9.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_19328]"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "history = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=100,\n",
        "  steps_per_epoch= len(training_set),\n",
        "  validation_steps= len(test_set)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_MYK-AYZO3F9",
        "outputId": "e690f109-e2f2-43b6-9175-01aa8f951e04"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-fc37dcf27d31>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "# plot the loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q99UXZma3-Y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d962e98b-38b0-48fd-df41-757614a0b63d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'backmoth': 0, 'healthy': 1, 'leafminer': 2, 'mildew': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confusion_matrix(model, validation_generator):\n",
        "    is_binary = len(validation_generator.class_indices) == 2\n",
        "    all_predictions = np.array([])\n",
        "    all_labels = np.array([])\n",
        "    for i in range(len(validation_generator)):\n",
        "        x_batch, y_batch = validation_generator[i]\n",
        "        predictions = model.predict(x_batch)\n",
        "        if (not is_binary):\n",
        "            predictions = np.argmax(predictions, axis=1)\n",
        "        else:\n",
        "            predictions = (predictions > .5) * 1\n",
        "        all_predictions = np.concatenate([all_predictions, predictions])\n",
        "\n",
        "        if (not is_binary):\n",
        "            labels = np.argmax(y_batch, axis = 1)\n",
        "        else:\n",
        "            labels = y_batch\n",
        "        all_labels = np.concatenate([all_labels, labels])\n",
        "\n",
        "    return tf.math.confusion_matrix(all_predictions, all_labels)"
      ],
      "metadata": {
        "id": "E4_0XoBbDnfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IY0FoDCQ6Tz",
        "outputId": "cb3edd9a-9ed6-4a15-ab5d-c140ec98755b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 45.2036 - accuracy: 0.4333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[45.20363235473633, 0.4333333373069763]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "Y_pred = model.predict_generator(test_set, 7)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "cm = confusion_matrix(test_set.classes, y_pred)\n",
        "print(cm)\n",
        "print(classification_report(test_set.classes, y_pred))\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_set.classes)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d3fd785-3ce0-4daf-95d9-bdf03f4fa7da",
        "id": "hltbbOkQHwtu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-2a2e21bfbb21>:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  Y_pred = model.predict_generator(test_set, 7)\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 1 2]\n",
            " [3 3 1 0]\n",
            " [0 3 3 3]\n",
            " [2 2 3 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.40      0.33         5\n",
            "           1       0.38      0.43      0.40         7\n",
            "           2       0.38      0.33      0.35         9\n",
            "           3       0.29      0.22      0.25         9\n",
            "\n",
            "    accuracy                           0.33        30\n",
            "   macro avg       0.33      0.35      0.33        30\n",
            "weighted avg       0.33      0.33      0.33        30\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2a2e21bfbb21>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         ax.set(\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.__qualname__}.set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;31m# Artist._update_set_signature_and_docstring() at the end of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0;31m# module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlack\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprenormalization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaintain\u001b[0m \u001b[0mbackcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m         return self._update_props(\n\u001b[0m\u001b[1;32m   1224\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{cls.__name__}.set() got an unexpected keyword argument \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \"{prop_name!r}\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1197\u001b[0m                         raise AttributeError(\n\u001b[1;32m   1198\u001b[0m                             errfmt.format(cls=type(self), prop_name=k))\n\u001b[0;32m-> 1199\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 f\"for the old name will be dropped %(removal)s.\")\n\u001b[1;32m    296\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# wrapper() must keep the same documented signature as func(): if we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1970\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (30)."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "Y_pred = model_1.predict_generator(test_data, 7)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "cm = confusion_matrix(test_data.classes, y_pred)\n",
        "print(cm)\n",
        "print(classification_report(test_data.classes, y_pred))\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_data.classes)\n",
        "disp.plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "18Fp6QRPDo6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "7b18eea9-80b0-4a86-8a76-7de7ab3b6b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f8d74f8b0008>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLkhVv07Bvqa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.utils import load_img, img_to_array\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size = (224, 224))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size = 32)\n",
        "\n",
        "  print(fn)\n",
        "\n",
        "  if classes[0, 0] == 0:\n",
        "    print('backmoth')\n",
        "  elif 0> classes[0, 1] <= 1:\n",
        "    print('leafminer')\n",
        "  elif 1 > classes [0, 2] <= 2:\n",
        "    print('mildew')\n",
        "  else:\n",
        "    print('sehat')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kABdnrjfCYTu"
      },
      "outputs": [],
      "source": [
        "# save it as a h5 file\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('model_resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4KAYyeQCeNP"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7JgWmCDP6Ij"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ9l9-RlP9vz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tXK_amEQBJA"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkW9wMp6QCl1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4OUDvKdQGVm"
      },
      "outputs": [],
      "source": [
        "model=load_model('model_resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjV3gwOERi4G"
      },
      "outputs": [],
      "source": [
        "img=image.load_img('/content/drive/MyDrive/TA/data/test/backmoth/Backmoth1.jpg',target_size=(224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3gUE5IHR4wv"
      },
      "outputs": [],
      "source": [
        "x=image.img_to_array(img)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NJl5jTER_k_"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix4MFjHESD4-"
      },
      "outputs": [],
      "source": [
        "x=x/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_-rEIH5SHd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x=np.expand_dims(x,axis=0)\n",
        "img_data=preprocess_input(x)\n",
        "img_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftIFfxKRSJUG"
      },
      "outputs": [],
      "source": [
        "model.predict(img_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcXtKDr_SQDW"
      },
      "outputs": [],
      "source": [
        "a=np.argmax(model.predict(img_data), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhaJ0wnxSTlx"
      },
      "outputs": [],
      "source": [
        "a==1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMpUjLkwSV1g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1UA5YEW83kte1a94_h14UHsV0F44OU-ZT",
      "authorship_tag": "ABX9TyNVEEwpS6q7YHC5PY1wBm4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}